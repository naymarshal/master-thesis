{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eecae1db-a2a9-4f43-81d1-7723695f52eb",
   "metadata": {},
   "source": [
    "**DATA PREPROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa67d66-edfe-40ed-8953-600002874c32",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c45d1e8-ee5f-4f31-864a-549409932cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from emoji import EMOJI_DATA \n",
    "import numpy as np\n",
    "import langdetect\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e5163-9f84-42e1-be7a-9401d6411096",
   "metadata": {},
   "source": [
    "Import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8a196a-cf60-4189-a61d-84d99e97c379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61065 records in the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>256990849</td>\n",
       "      <td>2/6/2024, 3:58:30 PM</td>\n",
       "      <td>10001</td>\n",
       "      <td>üç∏firsts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>256990849</td>\n",
       "      <td>2/6/2024, 3:58:38 PM</td>\n",
       "      <td>10002</td>\n",
       "      <td>lbcb‚ù§Ô∏è‚Äçü©π</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>261362701</td>\n",
       "      <td>2/6/2024, 4:07:48 PM</td>\n",
       "      <td>10003</td>\n",
       "      <td>Cb ‚ù§Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1</td>\n",
       "      <td>48983127189</td>\n",
       "      <td>2/6/2024, 6:07:41 PM</td>\n",
       "      <td>10004</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1</td>\n",
       "      <td>260048784</td>\n",
       "      <td>2/7/2024, 3:28:33 AM</td>\n",
       "      <td>10005</td>\n",
       "      <td>LBLB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id      user_id          publish_date  comment_id comment_text\n",
       "0      A1    256990849  2/6/2024, 3:58:30 PM       10001      üç∏firsts\n",
       "1      A1    256990849  2/6/2024, 3:58:38 PM       10002     lbcb‚ù§Ô∏è‚Äçü©π\n",
       "2      A1    261362701  2/6/2024, 4:07:48 PM       10003        Cb ‚ù§Ô∏è\n",
       "3      A1  48983127189  2/6/2024, 6:07:41 PM       10004         Nice\n",
       "4      A1    260048784  2/7/2024, 3:28:33 AM       10005         LBLB"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to read csv file into dataset\n",
    "def read_csv_file(file): \n",
    "    dataset = pd.read_csv(file,header=0)\n",
    "    return dataset\n",
    "    \n",
    "df = read_csv_file(r\"C:\\Users\\nayma\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\thesis\\total.csv\")\n",
    "\n",
    "# Check the dataset\n",
    "print(len(df.index), \"records in the dataset\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c5b14-59c0-4857-af98-d8b64ddf6d2c",
   "metadata": {},
   "source": [
    "Work only with relevant columns and make comment text column a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353ad5cc-ec8f-47a7-8e9c-6b719292c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['post_id','comment_id','comment_text']]\n",
    "df['comment_text'] = df['comment_text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab1d31-e2d1-48d3-af7e-58dbb163b467",
   "metadata": {},
   "source": [
    "**Data cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9600401-ad64-4f79-bc3c-8fedc5958837",
   "metadata": {},
   "source": [
    "Keep only words uppercased or lowered, i.e. lower capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88313c3c-c8c1-4424-88b4-3ce075f9ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function lower some words\n",
    "def lower_words(column):\n",
    "    lowered = []\n",
    "    pattern = r'\\b(?![a-z]+\\b|[A-Z]+\\b)[a-zA-Z]+'\n",
    "    for comment in column:\n",
    "        for word in re.findall(pattern, comment):\n",
    "            comment = comment.replace(word, word.lower())\n",
    "        lowered.append(comment)\n",
    "    return lowered\n",
    "    \n",
    "df['comment_text'] = lower_words(df['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7397fe-2ba1-4f0d-a360-7a5499b09678",
   "metadata": {},
   "source": [
    "Add spaces between emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec434988-499a-4e93-9cf7-a08bf4a7cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search your emoji\n",
    "def is_emoji(s):\n",
    "    return s in EMOJI_DATA\n",
    "\n",
    "# Add space around emoji\n",
    "def add_space(column):\n",
    "    column_spaced = []\n",
    "    for comment in column:\n",
    "        comment = ''.join(' ' + char + ' ' if is_emoji(char) else char for char in comment).strip()\n",
    "        column_spaced.append(comment)\n",
    "    return column_spaced\n",
    "\n",
    "df['comment_text'] = add_space(df['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e9e254-82e8-4904-a418-f9ad373846a7",
   "metadata": {},
   "source": [
    "Remove mentions, URLs, hash symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fcac24-6b24-4d35-a1a6-406749b2e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function @\n",
    "def remove_mention(column):\n",
    "    without_add = []\n",
    "    for comment in column:\n",
    "        comment = re.sub(r\"(?:\\@|@)\\S+\", \"\",comment) \n",
    "        without_add.append(comment)\n",
    "    return without_add\n",
    "\n",
    "\n",
    "# Define function URL\n",
    "def remove_url(column):\n",
    "    without_url = []\n",
    "    for comment in column:\n",
    "        comment = re.sub(r\"(?:\\@|https?\\://)\\S+\",\"\",comment)  \n",
    "        without_url.append(comment)\n",
    "    return without_url\n",
    "\n",
    "\n",
    "# Define function #\n",
    "def remove_hashtag(column):\n",
    "    without_hash = []\n",
    "    for comment in column:\n",
    "        comment = re.sub(r\"#\", \"\",comment) \n",
    "        without_hash.append(comment)\n",
    "    return without_hash\n",
    "\n",
    "\n",
    "# Mentions: removing @mention\n",
    "df['comment_text'] = remove_mention(df['comment_text'])\n",
    "\n",
    "# URLs: removing http://urlwhatever.com\n",
    "df['comment_text'] = remove_url(df['comment_text'])\n",
    "\n",
    "# Hashtag symbol: #\n",
    "df['comment_text'] = remove_hashtag(df['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e4e59e-8575-443a-b69f-a4cf6020aeca",
   "metadata": {},
   "source": [
    "Remove leading and trailing blank spaces in string and removing extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cecfe81-bd32-45ac-b6d7-d703b415d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function remove blank spaces\n",
    "def blank_spaces(column):\n",
    "    without_space = []\n",
    "    for comment in column:\n",
    "        comment = comment.replace(r' {2,}',' ')\n",
    "        comment = comment.strip()\n",
    "        without_space.append(comment)\n",
    "    return without_space\n",
    "    \n",
    "df['comment_text'] = blank_spaces(df['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8529dd3-9aff-4abf-91c2-b928e4b4eb71",
   "metadata": {},
   "source": [
    "Missing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f5e3de-a499-4611-9449-92e2e45d014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_drop = ['.','nan','NAN','']\n",
    "\n",
    "for i in list_drop:\n",
    "    df = df.drop(df[df['comment_text'] == i].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c71341-ca35-44ab-b957-6b0fe97ba88b",
   "metadata": {},
   "source": [
    "Most repeated comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3155d1ac-34d4-46d0-84bd-9bc5955e54af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text\n",
       "‚ù§ Ô∏è                            1447\n",
       "üòç                              1067\n",
       "üòç  üòç  üòç                        1009\n",
       "‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è                     810\n",
       "üî•  üî•  üî•                         777\n",
       "üî•                               775\n",
       "üòç  üòç                            738\n",
       "cb                              626\n",
       "‚ù§ Ô∏è ‚ù§ Ô∏è                         533\n",
       "üòç  üòç  üòç  üòç                      487\n",
       "üî•  üî•                            478\n",
       "üî•  üî•  üî•  üî•                      404\n",
       "lb                              397\n",
       "‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è                 321\n",
       "üòç  üòç  üòç  üòç  üòç                   237\n",
       "üî•  üî•  üî•  üî•  üî•                   211\n",
       "‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è             199\n",
       "first                           182\n",
       "beautiful                       168\n",
       "hi                              168\n",
       "üòÇ                               145\n",
       "üëè                               143\n",
       "‚ù§ Ô∏è üî•                           137\n",
       "üôå                               124\n",
       "üòç  üòç  üòç  üòç  üòç  üòç                121\n",
       "‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è         120\n",
       "üî•  üî•  üî•  üî•  üî•  üî•                109\n",
       "üî•  ‚ù§ Ô∏è                          109\n",
       "row                              99\n",
       "CB                               95\n",
       "üòÇ  üòÇ  üòÇ                          90\n",
       "üòç  ‚ù§ Ô∏è                           86\n",
       "gorgeous                         85\n",
       "üòç  üòç  üòç  üòç  üòç  üòç  üòç              82\n",
       "üòç  üî•                             80\n",
       "nice                             79\n",
       "üòÆ                                78\n",
       "‚ù§ Ô∏è üòç                            75\n",
       "rows                             73\n",
       "lblb                             72\n",
       "üñ§                                71\n",
       "ü§ç                                70\n",
       "‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è      69\n",
       "stunning                         68\n",
       "beautiful  ‚ù§ Ô∏è                   66\n",
       "üëè  üëè  üëè                          63\n",
       "üëè  üëè                             58\n",
       "üòÇ  üòÇ                             57\n",
       "lbbb                             56\n",
       "wow                              55\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_text.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce530627-c53f-4608-8f72-c3c333c9dd39",
   "metadata": {},
   "source": [
    "Handle slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5449e77-757f-4877-8c7b-9408dff70f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary with slang terminology\n",
    "dict_slang = {'cb': 'comment back', 'lb': 'like back', 'fb': 'follow back', 'first': 'first comment', \n",
    "              'first only': 'like my first picture', 'row': 'like back', 'rows': 'like back', 'instant': 'like back', \n",
    "              'row for row': 'like back','lblb':'like back', 'lbbb':'like back'}\n",
    "\n",
    "dict_slang_up = {key.upper(): value.upper() for key,value in dict_slang.items()}\n",
    "\n",
    "# Define function to merge dictionaries\n",
    "def merge(x,*y):\n",
    "    r = x.copy()\n",
    "    for z in y:\n",
    "        r.update(z)\n",
    "    return r\n",
    "    \n",
    "dict_slang = merge(dict_slang, dict_slang_up)\n",
    "\n",
    "for key, value in dict_slang.items():\n",
    "    df.loc[df['comment_text'] == key, 'comment_text'] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8484d-e508-4fc4-84b9-0ffaf0d0bf64",
   "metadata": {},
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4781261-c29a-48d5-bf95-eeae8738516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37339 records after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['comment_text'])\n",
    "\n",
    "print(len(df.index), \"records after removing duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fccad6-9ac7-4b68-9aaa-233bc89367ee",
   "metadata": {},
   "source": [
    "**Selection data in English and conveying sentiment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd0998-712f-4c37-9c91-59127d3bc5f0",
   "metadata": {},
   "source": [
    "Detect language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b8c706-bc81-43c5-9be4-57a50d8a2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function detect language\n",
    "def detect_language_with_langdetect(column):\n",
    "    lang_list = []\n",
    "    for comment in column:\n",
    "        try:\n",
    "            lang = langdetect.detect(comment) \n",
    "        except:\n",
    "            lang = \"most_emoji\"\n",
    "        lang_list. append(lang)\n",
    "    return lang_list\n",
    "\n",
    "\n",
    "df['lang'] = detect_language_with_langdetect(df['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aacf919-dd6d-4d06-97b5-1034a069b148",
   "metadata": {},
   "source": [
    "Separate in English, mostly emoji, and the rest of languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92eb6558-492b-40be-85c7-68a29143a346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:  15985 , mostly emoji or no language:  4416 , labelled in other languages:  16938\n"
     ]
    }
   ],
   "source": [
    "df_en = df[df['lang'] == 'en']\n",
    "df_mo = df[df['lang'] == 'most_emoji']\n",
    "df_else = df[(df['lang'] != 'en') & (df['lang'] != 'most_emoji')]\n",
    "print(\"English: \", len(df_en.index), \", mostly emoji or no language: \", len(df_mo.index), \", labelled in other languages: \", len(df_else.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71abe3-96b3-4da7-86e4-78657fef3068",
   "metadata": {},
   "source": [
    "**Refining language classification in df_else**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce08a3-4fba-4ac3-94c7-c8af8fdf5c69",
   "metadata": {},
   "source": [
    "Removing non latin alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3fe18aa-d0f2-4647-9096-b0b023519547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of languages with non latin alphabets\n",
    "non_latin_script = ['ar', 'bg', 'bn', 'el', 'fa', 'gu', 'he', 'hi', 'ja', 'ko', 'mk', 'mr', 'ne', 'ru', 'te', 'th', 'uk', 'ur', 'zh-cn', 'zh-tw']\n",
    "\n",
    "df_else = df_else[~df_else['lang'].isin(non_latin_script)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01d31204-6527-4b6b-a0a7-d6a233fe2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd round of detecting language of comments\n",
    "df_else['lang2.0'] = detect_language_with_langdetect(df_else['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f358354-d2ee-4ddc-b93c-9e60f0bbdc69",
   "metadata": {},
   "source": [
    "Appoint new language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb2f344-738f-461c-b76d-ea41e470168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_else.loc[df_else['lang2.0'] == 'en', 'lang'] = 'en'\n",
    "df_else = df_else.loc[:, df_else.columns!='lang2.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3c007-c099-4ced-a501-d882c7d24b75",
   "metadata": {},
   "source": [
    "Count most frequent words in strings to identify English comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "673d2daa-9c93-4ff2-ac9b-dbaebcbc6030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ô∏è', 4792),\n",
       " ('‚ù§', 4644),\n",
       " ('üî•', 4570),\n",
       " ('üòç', 4063),\n",
       " ('you', 1036),\n",
       " ('üòÇ', 779),\n",
       " ('üëè', 682),\n",
       " ('love', 659),\n",
       " ('so', 600),\n",
       " ('üôå', 585),\n",
       " ('i', 558),\n",
       " ('a', 540),\n",
       " ('beautiful', 523),\n",
       " ('que', 494),\n",
       " ('‚ú®', 390),\n",
       " ('de', 380),\n",
       " ('my', 367),\n",
       " ('la', 355),\n",
       " ('ü§ç', 335),\n",
       " ('look', 329),\n",
       " ('me', 321),\n",
       " ('gorgeous', 319),\n",
       " ('üñ§', 297),\n",
       " ('kim', 278),\n",
       " ('üíã', 275),\n",
       " ('like', 252),\n",
       " ('te', 252),\n",
       " ('üòò', 251),\n",
       " ('queen', 236),\n",
       " ('ü•∞', 233),\n",
       " ('are', 219),\n",
       " ('u', 214),\n",
       " ('stunning', 214),\n",
       " ('üòÆ', 205),\n",
       " ('mi', 199),\n",
       " ('üåπ', 199),\n",
       " ('y', 188),\n",
       " ('no', 187),\n",
       " ('girl', 182),\n",
       " ('‚ô•', 178),\n",
       " ('kendall', 178),\n",
       " ('rows', 175),\n",
       " ('wow', 171),\n",
       " ('kylie', 170),\n",
       " ('üèª', 170),\n",
       " ('it', 166),\n",
       " ('en', 162),\n",
       " ('good', 161),\n",
       " ('your', 161),\n",
       " ('nice', 158),\n",
       " ('üíï', 156),\n",
       " ('linda', 153),\n",
       " ('Ô∏è\\u200d', 148),\n",
       " ('hermosa', 145),\n",
       " ('üò¢', 144),\n",
       " ('row', 144),\n",
       " ('\\u200d', 137),\n",
       " ('el', 133),\n",
       " ('looking', 133),\n",
       " ('pretty', 131),\n",
       " ('üíñ', 131),\n",
       " ('üò≠', 131),\n",
       " ('se', 130),\n",
       " ('ü´∂', 130),\n",
       " ('amazing', 125),\n",
       " ('tu', 123),\n",
       " ('es', 123),\n",
       " ('ü§©', 122),\n",
       " ('lb', 120),\n",
       " ('hot', 119),\n",
       " ('omg', 118),\n",
       " ('just', 116),\n",
       " ('looks', 115),\n",
       " ('üèº', 115),\n",
       " ('o', 114),\n",
       " ('üëë', 114),\n",
       " ('is', 112),\n",
       " ('amo', 110),\n",
       " ('in', 110),\n",
       " ('cute', 108),\n",
       " ('ü§£', 105),\n",
       " ('to', 104),\n",
       " ('baby', 102),\n",
       " ('cb', 98),\n",
       " ('yes', 98),\n",
       " ('damn', 96),\n",
       " ('sexy', 94),\n",
       " ('for', 92),\n",
       " ('üèΩ', 91),\n",
       " ('üòó', 91),\n",
       " ('ü§§', 89),\n",
       " ('üí©', 89),\n",
       " ('go', 87),\n",
       " ('lo', 87),\n",
       " ('and', 86),\n",
       " ('como', 85),\n",
       " ('e', 85),\n",
       " ('khloe', 83),\n",
       " ('kourt', 82),\n",
       " ('un', 81)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_else_comm = df_else['comment_text'].str.lower()\n",
    "Counter(\" \".join(df_else_comm).split()).most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09765c41-0367-43fe-a1a0-12035cfdf120",
   "metadata": {},
   "source": [
    "Labeling comments as English if contain most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e954cce-ba58-4f6a-9e2c-65766ceaf4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang2.0\n",
      "      11352\n",
      "en     4531\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define list of most common words that are in English\n",
    "common_en = [\"you\", \"love\", \"beautiful\", \"look\", \"just\", \"gorgeous\", \"like\", \"stunning\", \"nice\", \"queen\", \"girl\", \"you\",\n",
    "            \"good\", \"looking\", \"looks\", \"amazing\", \"pretty\", \"you're\", \"hot\", \"cute\", \"omg\", \"sexy\", \"very\"]\n",
    "\n",
    "common_en_up = [x.upper() for x in common_en]\n",
    "\n",
    "common_en = common_en + common_en_up\n",
    "\n",
    "df_else['lang2.0'] = \"\"\n",
    "\n",
    "for x in common_en:\n",
    "    df_else.loc[df_else['comment_text'].str.contains(x),'lang2.0'] = 'en'\n",
    "\n",
    "counts = df_else['lang2.0'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e303b-cb0a-4e53-ae26-0636cff9d49b",
   "metadata": {},
   "source": [
    "Check if labeling is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f8c2b9e-2c95-418f-8053-e25672993715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1</td>\n",
       "      <td>10004</td>\n",
       "      <td>nice</td>\n",
       "      <td>pl</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1</td>\n",
       "      <td>10005</td>\n",
       "      <td>LIKE BACK</td>\n",
       "      <td>vi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A1</td>\n",
       "      <td>10020</td>\n",
       "      <td>i love you  üòç  üòç</td>\n",
       "      <td>cs</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>A1</td>\n",
       "      <td>10074</td>\n",
       "      <td>fashion queen ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A1</td>\n",
       "      <td>10096</td>\n",
       "      <td>this era  üî• natural look I‚Äôm just obsessed  üòç</td>\n",
       "      <td>et</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A1</td>\n",
       "      <td>10098</td>\n",
       "      <td>nice pick!</td>\n",
       "      <td>pl</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>A1</td>\n",
       "      <td>10104</td>\n",
       "      <td>like back</td>\n",
       "      <td>hr</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>A1</td>\n",
       "      <td>10117</td>\n",
       "      <td>beautiful.</td>\n",
       "      <td>ro</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>A1</td>\n",
       "      <td>10134</td>\n",
       "      <td>soo good</td>\n",
       "      <td>so</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>A1</td>\n",
       "      <td>10135</td>\n",
       "      <td>you look beautiful</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>A1</td>\n",
       "      <td>10174</td>\n",
       "      <td>lol girl no</td>\n",
       "      <td>it</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>A1</td>\n",
       "      <td>10227</td>\n",
       "      <td>you‚Äôre so pretty  ü•π</td>\n",
       "      <td>sk</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>A1</td>\n",
       "      <td>10230</td>\n",
       "      <td>HOT miss jenner</td>\n",
       "      <td>no</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>A1</td>\n",
       "      <td>10233</td>\n",
       "      <td>queen ‚ù§ Ô∏è üî•</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>A1</td>\n",
       "      <td>10241</td>\n",
       "      <td>I love youuuuu</td>\n",
       "      <td>fi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>A1</td>\n",
       "      <td>10244</td>\n",
       "      <td>V niceee  ‚ù§ Ô∏è  ü•∞</td>\n",
       "      <td>nl</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>A1</td>\n",
       "      <td>10248</td>\n",
       "      <td>youz</td>\n",
       "      <td>sw</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>A1</td>\n",
       "      <td>10252</td>\n",
       "      <td>‚ù§ Ô∏è stunning</td>\n",
       "      <td>fi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>A1</td>\n",
       "      <td>10254</td>\n",
       "      <td>cute  ü•∞  üçì</td>\n",
       "      <td>ro</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>A1</td>\n",
       "      <td>10270</td>\n",
       "      <td>gorgeous  ‚ù§ Ô∏è</td>\n",
       "      <td>af</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>A1</td>\n",
       "      <td>10281</td>\n",
       "      <td>I love u</td>\n",
       "      <td>sl</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>A1</td>\n",
       "      <td>10285</td>\n",
       "      <td>gorgeous  üòç  üòç  üòç  üòç</td>\n",
       "      <td>af</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>A1</td>\n",
       "      <td>10287</td>\n",
       "      <td>QUEEN IN RED ‚ù§ Ô∏è‚Äç üî•  üî•</td>\n",
       "      <td>so</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>A1</td>\n",
       "      <td>10292</td>\n",
       "      <td>STUNNING</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>A1</td>\n",
       "      <td>10313</td>\n",
       "      <td>I love you kizzle  ‚ù§ Ô∏è</td>\n",
       "      <td>sl</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>A1</td>\n",
       "      <td>10325</td>\n",
       "      <td>feel like u inspired this look  ‚ù§ Ô∏è</td>\n",
       "      <td>af</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>A1</td>\n",
       "      <td>10336</td>\n",
       "      <td>stunning bbg</td>\n",
       "      <td>no</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>A1</td>\n",
       "      <td>10353</td>\n",
       "      <td>went from king kylie, to queen kylie üî•</td>\n",
       "      <td>af</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>A1</td>\n",
       "      <td>10363</td>\n",
       "      <td>does not even look like young  beautiful kylie.</td>\n",
       "      <td>af</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>A1</td>\n",
       "      <td>10424</td>\n",
       "      <td>you are beautiful, my kylie</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>A1</td>\n",
       "      <td>10463</td>\n",
       "      <td>queen  ‚ù§ Ô∏è</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>A1</td>\n",
       "      <td>10468</td>\n",
       "      <td>stunning in red ‚ù§ Ô∏è</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>A1</td>\n",
       "      <td>10473</td>\n",
       "      <td>love ‚ù§ Ô∏è</td>\n",
       "      <td>sl</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>A1</td>\n",
       "      <td>10475</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>A1</td>\n",
       "      <td>10515</td>\n",
       "      <td>beautiful woman i want you</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>A1</td>\n",
       "      <td>10523</td>\n",
       "      <td>stunning  üî•</td>\n",
       "      <td>no</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>A1</td>\n",
       "      <td>10525</td>\n",
       "      <td>red on you&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</td>\n",
       "      <td>cy</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>A1</td>\n",
       "      <td>10530</td>\n",
       "      <td>gorgeous  üòç  üëÑ  ‚ù§ Ô∏è</td>\n",
       "      <td>af</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>A1</td>\n",
       "      <td>10572</td>\n",
       "      <td>love  you are stunning</td>\n",
       "      <td>no</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>A1</td>\n",
       "      <td>10584</td>\n",
       "      <td>PRETTY IN RED ‚ù§ Ô∏è</td>\n",
       "      <td>id</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>A1</td>\n",
       "      <td>10607</td>\n",
       "      <td>stunning  üòÆ ‚Äç üí®  ‚ù§ Ô∏è</td>\n",
       "      <td>no</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>A1</td>\n",
       "      <td>10611</td>\n",
       "      <td>sexy mama  üî•</td>\n",
       "      <td>so</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>A1</td>\n",
       "      <td>10612</td>\n",
       "      <td>gorgeous glam &amp; dazzling</td>\n",
       "      <td>hr</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>A1</td>\n",
       "      <td>10625</td>\n",
       "      <td>looks like a hostel I lived in.</td>\n",
       "      <td>et</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>A1</td>\n",
       "      <td>10674</td>\n",
       "      <td>stunning  ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è</td>\n",
       "      <td>no</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>A1</td>\n",
       "      <td>10713</td>\n",
       "      <td>I love you kylie  üòç  üòç  üòç  üòç  üòç  üòç</td>\n",
       "      <td>sk</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>A1</td>\n",
       "      <td>10716</td>\n",
       "      <td>gorgeous  üòç</td>\n",
       "      <td>af</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>A1</td>\n",
       "      <td>10717</td>\n",
       "      <td>my girl  ‚ù§ Ô∏è</td>\n",
       "      <td>cy</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>A1</td>\n",
       "      <td>10726</td>\n",
       "      <td>sexy queen beautiful</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>A1</td>\n",
       "      <td>10738</td>\n",
       "      <td>okkkaayy gorgeous  üòç  üòç  üôå</td>\n",
       "      <td>af</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id  comment_id                                     comment_text lang  \\\n",
       "3        A1       10004                                             nice   pl   \n",
       "4        A1       10005                                        LIKE BACK   vi   \n",
       "19       A1       10020                                 i love you  üòç  üòç   cs   \n",
       "73       A1       10074                        fashion queen ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è   fr   \n",
       "95       A1       10096    this era  üî• natural look I‚Äôm just obsessed  üòç   et   \n",
       "97       A1       10098                                       nice pick!   pl   \n",
       "103      A1       10104                                        like back   hr   \n",
       "116      A1       10117                                       beautiful.   ro   \n",
       "133      A1       10134                                         soo good   so   \n",
       "134      A1       10135                               you look beautiful   fr   \n",
       "173      A1       10174                                      lol girl no   it   \n",
       "226      A1       10227                              you‚Äôre so pretty  ü•π   sk   \n",
       "229      A1       10230                                  HOT miss jenner   no   \n",
       "232      A1       10233                                      queen ‚ù§ Ô∏è üî•   es   \n",
       "240      A1       10241                                   I love youuuuu   fi   \n",
       "243      A1       10244                                 V niceee  ‚ù§ Ô∏è  ü•∞   nl   \n",
       "247      A1       10248                                             youz   sw   \n",
       "251      A1       10252                                     ‚ù§ Ô∏è stunning   fi   \n",
       "253      A1       10254                                       cute  ü•∞  üçì   ro   \n",
       "269      A1       10270                                    gorgeous  ‚ù§ Ô∏è   af   \n",
       "280      A1       10281                                         I love u   sl   \n",
       "284      A1       10285                             gorgeous  üòç  üòç  üòç  üòç   af   \n",
       "286      A1       10287                           QUEEN IN RED ‚ù§ Ô∏è‚Äç üî•  üî•   so   \n",
       "291      A1       10292                                         STUNNING   de   \n",
       "312      A1       10313                           I love you kizzle  ‚ù§ Ô∏è   sl   \n",
       "324      A1       10325              feel like u inspired this look  ‚ù§ Ô∏è   af   \n",
       "335      A1       10336                                     stunning bbg   no   \n",
       "352      A1       10353           went from king kylie, to queen kylie üî•   af   \n",
       "362      A1       10363  does not even look like young  beautiful kylie.   af   \n",
       "423      A1       10424                      you are beautiful, my kylie   fr   \n",
       "462      A1       10463                                       queen  ‚ù§ Ô∏è   es   \n",
       "467      A1       10468                              stunning in red ‚ù§ Ô∏è   en   \n",
       "472      A1       10473                                         love ‚ù§ Ô∏è   sl   \n",
       "474      A1       10475                                        beautiful   fr   \n",
       "514      A1       10515                       beautiful woman i want you   en   \n",
       "522      A1       10523                                      stunning  üî•   no   \n",
       "524      A1       10525                               red on you>>>>>>>>   cy   \n",
       "529      A1       10530                              gorgeous  üòç  üëÑ  ‚ù§ Ô∏è   af   \n",
       "571      A1       10572                           love  you are stunning   no   \n",
       "583      A1       10584                                PRETTY IN RED ‚ù§ Ô∏è   id   \n",
       "606      A1       10607                             stunning  üòÆ ‚Äç üí®  ‚ù§ Ô∏è   no   \n",
       "610      A1       10611                                     sexy mama  üî•   so   \n",
       "611      A1       10612                         gorgeous glam & dazzling   hr   \n",
       "624      A1       10625                  looks like a hostel I lived in.   et   \n",
       "673      A1       10674                    stunning  ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è ‚ù§ Ô∏è   no   \n",
       "712      A1       10713               I love you kylie  üòç  üòç  üòç  üòç  üòç  üòç   sk   \n",
       "715      A1       10716                                      gorgeous  üòç   af   \n",
       "716      A1       10717                                     my girl  ‚ù§ Ô∏è   cy   \n",
       "725      A1       10726                             sexy queen beautiful   fr   \n",
       "737      A1       10738                       okkkaayy gorgeous  üòç  üòç  üôå   af   \n",
       "\n",
       "    lang2.0  \n",
       "3        en  \n",
       "4        en  \n",
       "19       en  \n",
       "73       en  \n",
       "95       en  \n",
       "97       en  \n",
       "103      en  \n",
       "116      en  \n",
       "133      en  \n",
       "134      en  \n",
       "173      en  \n",
       "226      en  \n",
       "229      en  \n",
       "232      en  \n",
       "240      en  \n",
       "243      en  \n",
       "247      en  \n",
       "251      en  \n",
       "253      en  \n",
       "269      en  \n",
       "280      en  \n",
       "284      en  \n",
       "286      en  \n",
       "291      en  \n",
       "312      en  \n",
       "324      en  \n",
       "335      en  \n",
       "352      en  \n",
       "362      en  \n",
       "423      en  \n",
       "462      en  \n",
       "467      en  \n",
       "472      en  \n",
       "474      en  \n",
       "514      en  \n",
       "522      en  \n",
       "524      en  \n",
       "529      en  \n",
       "571      en  \n",
       "583      en  \n",
       "606      en  \n",
       "610      en  \n",
       "611      en  \n",
       "624      en  \n",
       "673      en  \n",
       "712      en  \n",
       "715      en  \n",
       "716      en  \n",
       "725      en  \n",
       "737      en  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_else[df_else['lang2.0'] == 'en'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e01b0-1cfc-478c-81ad-490357eef371",
   "metadata": {},
   "source": [
    "Appoint English comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66aee97e-be49-4a0c-bca7-be877c360f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4727\n"
     ]
    }
   ],
   "source": [
    "df_else.loc[df_else['lang2.0'] == 'en', 'lang'] = 'en'\n",
    "df_else = df_else.loc[:, df_else.columns!='lang2.0']\n",
    "\n",
    "df_else_en = df_else[df_else['lang'] == 'en']\n",
    "print(len(df_else_en.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03f359-7d2f-495f-820b-3e68af7851a5",
   "metadata": {},
   "source": [
    "**Removing comments without any text or emoji from df_mo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d9f0119-a799-4582-b814-ada0841056f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nayma\\AppData\\Local\\Temp\\ipykernel_27600\\2592736472.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mo['drop_condition'] = drop\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>drop_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47192</th>\n",
       "      <td>D5</td>\n",
       "      <td>57193</td>\n",
       "      <td>........</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47630</th>\n",
       "      <td>D5</td>\n",
       "      <td>57631</td>\n",
       "      <td>,</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47636</th>\n",
       "      <td>D5</td>\n",
       "      <td>57637</td>\n",
       "      <td>,.</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47638</th>\n",
       "      <td>D5</td>\n",
       "      <td>57639</td>\n",
       "      <td>.&gt;,</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47639</th>\n",
       "      <td>D5</td>\n",
       "      <td>57640</td>\n",
       "      <td>,,,,&lt;%&gt;,</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47645</th>\n",
       "      <td>D5</td>\n",
       "      <td>57646</td>\n",
       "      <td>.,</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48417</th>\n",
       "      <td>D5</td>\n",
       "      <td>58418</td>\n",
       "      <td>·àÄ·ã≠</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48655</th>\n",
       "      <td>D5</td>\n",
       "      <td>58656</td>\n",
       "      <td>06?</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48888</th>\n",
       "      <td>D5</td>\n",
       "      <td>58889</td>\n",
       "      <td>7250431439</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49838</th>\n",
       "      <td>D5</td>\n",
       "      <td>59839</td>\n",
       "      <td>7</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50732</th>\n",
       "      <td>D5</td>\n",
       "      <td>60733</td>\n",
       "      <td>ùôÅùôßùôöùôö</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52841</th>\n",
       "      <td>E1</td>\n",
       "      <td>62842</td>\n",
       "      <td>¬Ω</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54705</th>\n",
       "      <td>E2</td>\n",
       "      <td>64706</td>\n",
       "      <td>Â¶àÂ¶à</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55001</th>\n",
       "      <td>E2</td>\n",
       "      <td>65002</td>\n",
       "      <td>üáß‚Äåüá™‚Äåüá¶‚Äåüá∫‚Äåüáπ‚ÄåüáÆ‚Äåüá´‚Äåüá∫‚Äåüá±‚Äå</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57172</th>\n",
       "      <td>E3</td>\n",
       "      <td>67173</td>\n",
       "      <td>7516188262</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57834</th>\n",
       "      <td>E3</td>\n",
       "      <td>67835</td>\n",
       "      <td>0</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59032</th>\n",
       "      <td>E3</td>\n",
       "      <td>69033</td>\n",
       "      <td>‚Öö</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59220</th>\n",
       "      <td>E3</td>\n",
       "      <td>69221</td>\n",
       "      <td>6</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59888</th>\n",
       "      <td>E3</td>\n",
       "      <td>69889</td>\n",
       "      <td>√ë9</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60383</th>\n",
       "      <td>E3</td>\n",
       "      <td>70384</td>\n",
       "      <td>??????????</td>\n",
       "      <td>most_emoji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id  comment_id        comment_text        lang  drop_condition\n",
       "47192      D5       57193            ........  most_emoji            True\n",
       "47630      D5       57631                   ,  most_emoji            True\n",
       "47636      D5       57637                  ,.  most_emoji            True\n",
       "47638      D5       57639                 .>,  most_emoji            True\n",
       "47639      D5       57640            ,,,,<%>,  most_emoji            True\n",
       "47645      D5       57646                  .,  most_emoji            True\n",
       "48417      D5       58418                  ·àÄ·ã≠  most_emoji            True\n",
       "48655      D5       58656                 06?  most_emoji            True\n",
       "48888      D5       58889          7250431439  most_emoji            True\n",
       "49838      D5       59839                   7  most_emoji            True\n",
       "50732      D5       60733                ùôÅùôßùôöùôö  most_emoji            True\n",
       "52841      E1       62842                   ¬Ω  most_emoji            True\n",
       "54705      E2       64706                  Â¶àÂ¶à  most_emoji            True\n",
       "55001      E2       65002  üáß‚Äåüá™‚Äåüá¶‚Äåüá∫‚Äåüáπ‚ÄåüáÆ‚Äåüá´‚Äåüá∫‚Äåüá±‚Äå  most_emoji            True\n",
       "57172      E3       67173          7516188262  most_emoji            True\n",
       "57834      E3       67835                   0  most_emoji            True\n",
       "59032      E3       69033                   ‚Öö  most_emoji            True\n",
       "59220      E3       69221                   6  most_emoji            True\n",
       "59888      E3       69889                  √ë9  most_emoji            True\n",
       "60383      E3       70384          ??????????  most_emoji            True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Marks True if comment does not contain emoji\n",
    "drop = []\n",
    "x = True\n",
    "i = 0\n",
    "column = df_mo.comment_text\n",
    "for comment in column:\n",
    "    i = i + 1\n",
    "    if emoji.emoji_count(comment) > 0:\n",
    "        x = False\n",
    "    else:\n",
    "        x = True\n",
    "    drop.append(x)  \n",
    "\n",
    "df_mo['drop_condition'] = drop\n",
    "\n",
    "# Check that comments dropped do not convey sentiment\n",
    "df_mo[df_mo['drop_condition'] == True].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24297038-9a19-40ab-a3e2-2dbc03cc5c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4306 are comments mostly composed by emojis.\n"
     ]
    }
   ],
   "source": [
    "# Updating df_on\n",
    "\n",
    "df_mo = df_mo.drop(df_mo[df_mo['drop_condition'] == True].index)\n",
    "df_mo = df_mo.loc[:, df_mo.columns!='drop_condition']\n",
    "\n",
    "print(len(df_mo.index), \"are comments mostly composed by emojis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70186024-a5c5-4ded-a50f-75d2d27917d0",
   "metadata": {},
   "source": [
    "**Final datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d0ce345-791a-430d-a21f-7c8e74263ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge subset in english with df_en\n",
    "df_en = pd.concat([df_en, df_else_en])\n",
    "df_en = df_en.sort_values(by=['comment_id'])\n",
    "\n",
    "# Merge df_en in english with emoji \n",
    "df = pd.concat([df_en, df_mo])\n",
    "df = df.sort_values(by=['comment_id'])\n",
    "\n",
    "# Remove subset in english from df_else\n",
    "df_else = df_else[df_else['lang'] != 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bf06d83-3088-43b9-9e4c-e0c7f8e1910d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25018 are clean comments in English or convey sentiment.\n"
     ]
    }
   ],
   "source": [
    "print(len(df.index), \"are clean comments in English or convey sentiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b802b2-8921-47ad-9c46-9983875570cc",
   "metadata": {},
   "source": [
    "Save dataset to work on further notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "487e9f57-e168-48c9-a48c-3917c533ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\nayma\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\thesis\\df.csv\", index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
